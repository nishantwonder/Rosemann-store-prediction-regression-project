{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Rosemann Retail  Store sales Prediction\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -**  Nishant kumar singh"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data set contains certain details of 1115 stores operating and non operating.\n",
        "\n",
        "In this project we have been provided with 2 CSV datasets for analysis purpose we wil merge the dataset on the basis of \"Store\" column.\n",
        "\n",
        "After merging we found 1017209 rows, 18 column.There was null values in certain columns like promo2sinceyear :-508031.After understanding the data set we applied data wranglling and feature engineering.\n",
        "\n",
        "After the treatment of dataset we perform Univariate analysis, Bivariante and multivariante analysis to understand the dataset.\n",
        "\n",
        "To build our model first we split the data set into 70:30 where 30 is test dataset.After the splliting we transform them and perform normalization.\n",
        "\n",
        "First we applied Linear regression and Ridge and lasso regression over the data set but we got maximum accuracy after the application of Random Forest."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied. You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import  StandardScaler,MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import math\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import ttest_ind,ttest_1samp,t,norm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "rossmann_df=pd.read_csv(\"/content/Rossmann Stores Data.csv\")\n",
        "store_df=pd.read_csv(\"/content/store.csv\")\n",
        "final_df = rossmann_df.merge(store_df,how='left', on='Store')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "rossmann_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.head()"
      ],
      "metadata": {
        "id": "uwh-Pj1CGySv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "id": "wWlCUTZlHAql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f\"the shape of first dataset id {rossmann_df.shape}\")\n",
        "print(f\"the shape of second dataset id {store_df.shape}\")\n",
        "print(f\"the shape of final dataset id {final_df.shape}\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "rossmann_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_df.info()"
      ],
      "metadata": {
        "id": "xGaN1BiIHzOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.info()"
      ],
      "metadata": {
        "id": "1Xz2HBR3H1Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "final_df.duplicated().value_counts()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "final_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "final_df.isnull().sum().plot.bar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the following columns contains the null values.\n",
        "\n",
        "CompetitionDistance 2642\n",
        "\n",
        "CompetitionOpenSinceMonth 323348\n",
        "\n",
        "CompetitionOpenSinceYear 323348\n",
        "\n",
        "Promo2SinceWeek 508031\n",
        "\n",
        "Promo2SinceYear 508031\n",
        "\n",
        "PromoInterval 508031\n",
        "\n",
        "This dataset does not contain duplicate values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "final_df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "final_df.describe().transpose"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 1017209 rows and 18 Columns out of which 13 columns are numerical"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in final_df.columns:\n",
        "  print(f\"The unique value for {i} is {len(final_df[i].unique())}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Assigning copy of final_df to a variable\n",
        "df1 = final_df.copy()\n",
        "# Assigning the data to a variable when shop is open\n",
        "df1_open = df1[df1['Open'] == 1].drop(columns=['Open'])\n",
        "# df1_open['SalesRate'] = df1_open['Sales']/df1_open['Customers']\n",
        "df1_open.describe()\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# approximately 17% observations are zero\n",
        "print(f\"Percentage of data when shops were closed : {round(len(df1[df1['Open'] == 0])/len(df1),4)*100}.\")\n",
        "\n",
        "\n",
        "# creating day, month, year columns\n",
        "plt.rcParams['figure.figsize'] = (5,3)\n",
        "# df1_open['day'] = df1_open['Date'].apply(lambda d: d.day)\n",
        "# df1_open['month'] = df1_open['Date'].apply(lambda m: m.month)\n",
        "df1_open['year'] = df1_open['Date'].apply(lambda y: y.year)"
      ],
      "metadata": {
        "id": "OB4WDf8BL7qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get top ten sum\n",
        "def top_10_sum(df,by_col,group_col):\n",
        "  return df.groupby(by_col)[group_col].sum().sort_values(ascending= False).head(10)"
      ],
      "metadata": {
        "id": "u_Iab9D0MCH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning top ten stores with highest sales to a variable\n",
        "top_10_stores_highest_sales = top_10_sum(df1_open,'Store','Sales').reset_index(name='sum of Sales')\n",
        "top_10_stores_highest_sales"
      ],
      "metadata": {
        "id": "xgIPgezVMItV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning top ten stores with highest customers to a variable\n",
        "top_10_stores_highest_cust = top_10_sum(df1_open,'Store','Customers').reset_index(name='sum of Customers')\n",
        "top_10_stores_highest_cust"
      ],
      "metadata": {
        "id": "f8HEcntcMNH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funcion which returns mean and median\n",
        "def get_mean_median(df,elem,col='StoreType'):\n",
        "  '''\n",
        "    takes dataset, column name and element and returns mean and median\n",
        "  '''\n",
        "  try:\n",
        "    return pd.concat([df[(df[col] == elem)].describe().iloc[1],\n",
        "                      df[(df[col] == elem)].describe().iloc[5]],\n",
        "                     axis = 1).rename( columns={'50%':'median'}).fillna('-')\n",
        "  except:\n",
        "    print('Invalid input')"
      ],
      "metadata": {
        "id": "WAMZxO4CMOJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Unique years are : ',df1_open['year'].unique())\n",
        "print(' ')\n",
        "# Getting mean and median for year 2013\n",
        "get_mean_median(df1_open,elem = 2013,col = 'year')"
      ],
      "metadata": {
        "id": "eBGbM_jhMYya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting mean and median for year 2014\n",
        "get_mean_median(df1_open,elem = 2014,col = 'year')"
      ],
      "metadata": {
        "id": "e4ECOLvCMlms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting mean and median for year 2015\n",
        "get_mean_median(df1_open,elem = 2015,col = 'year')"
      ],
      "metadata": {
        "id": "OabVbCo2Mmls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique values in column DayOfWeek\n",
        "print('Unique values in the column DayOfWeek : ',df1['DayOfWeek'].unique())\n",
        "# Mean and median for Day of week is 1\n",
        "get_mean_median(df1_open,1,'DayOfWeek')"
      ],
      "metadata": {
        "id": "GLV0v8GzNN6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean and median for Day of week is 2\n",
        "get_mean_median(df1_open,2,'DayOfWeek')"
      ],
      "metadata": {
        "id": "qbtZheJJNSkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean and median for Day of week is 3\n",
        "get_mean_median(df1_open,3,'DayOfWeek')"
      ],
      "metadata": {
        "id": "2Y8bnAowN2jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean and median for Day of week is 4\n",
        "get_mean_median(df1_open,4,'DayOfWeek')"
      ],
      "metadata": {
        "id": "XEKwj9HiN6GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean and median for Day of week is 5\n",
        "get_mean_median(df1_open,5,'DayOfWeek')"
      ],
      "metadata": {
        "id": "kBcBiiPJOASo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean and median for Day of week is 6\n",
        "get_mean_median(df1_open,6,'DayOfWeek')"
      ],
      "metadata": {
        "id": "AnW_bMnkOEN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean and median for Day of week is 7\n",
        "get_mean_median(df1_open,7,'DayOfWeek')"
      ],
      "metadata": {
        "id": "PaHmSfZaORnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average sales groupby the column StateHoliday\n",
        "print('Unique values in column StateHoliday : ',df1['StateHoliday'].unique(),'\\n')\n",
        "df1_open.groupby(['StateHoliday'])['Sales'].mean().reset_index()"
      ],
      "metadata": {
        "id": "RLAMoHjlOWvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average sale groupby the column StoreType\n",
        "print('Unique values in column StoreType : ',df1['StoreType'].unique(),'\\n')\n",
        "df1_open.groupby(['StoreType'])['Sales'].mean().reset_index()"
      ],
      "metadata": {
        "id": "8DAZntTPOaf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.rcParams['figure.figsize'] =(20,4)\n",
        "# Before log transformation\n",
        "sns.distplot(final_df['Sales'])\n",
        "plt.title('Distribution of Sales')\n",
        "plt.show()\n",
        "print('\\n')\n",
        "\n",
        "# After log transformation\n",
        "sns.distplot(np.log2(final_df['Sales']+1))\n",
        "plt.title('Distribution of Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution charts shows how data is distributed on the axis. I picked this chart to check the distribution about the target variable."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From that chart I found that the Sales column was very close to normal distribution and also it has double peak head it is because there are lot of 0. After log transformation I found that the distribution became more closer to Normal distribution."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the column is normally distributed so it will be very helpfull when ML algorithm will be applied after deleting those observations which is zero, it will give good accuracy. Yes,because there are many zeros it will lead to bad accuracy when applying machine learning algorith without dropping them."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Sum of Sales from day 1 to day 7\n",
        "plt.rcParams['figure.figsize'] = (8,8)\n",
        "final_df.groupby(['DayOfWeek'])['Sales'].sum().plot.pie(shadow =True,explode=[0.03,0.03,0.03,0.03,0.03,0.03,0.03], autopct='%0.1f%%',colors={'red','white','green'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie chart shows part to whole relationship in the data. I picked this chart to see percentage of Sales for different days."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found that sum of sales are maximum at day 1 and minimum at day 7. I think it is because at day 7 most of the time shop not open because of sunday so the sale is minimum and since the day 1 is monday therefore poeple buys more and more because many people could not buy anything at sunday."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes on day 7 sale is minimun but when we see mean sale then it is close to normal day therefore I can say that lot of the customers also want to buy things on day 7."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# Sales comparison for promotional and non promotional\n",
        "final_df.groupby(['Promo'])['Sales'].mean().plot.pie(shadow =True,explode=[0.03,0.03], autopct='%0.1f%%',colors={'red','white'})\n",
        "plt.title('Promo vs Non Promo')\n",
        "plt.xlabel('Promo')\n",
        "plt.ylabel('Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart express part to whole relationship of the data therefore I picked this chart to see the percentage of sale for promo and non promo."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case of promo sale is 64.5% and in another case sale is just 35.5%."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, I found that in case when there is non promo the sale is lower therefore promo play important role with sales."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "final_df.groupby(['Open'])['Sales'].mean().plot.pie(shadow =True,explode=[0,0.1], autopct='%0.1f%%',colors={'red'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart shows part to whole relationship in the data I picked this chart to check percentage of mean sales when shop is opened/closed."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found that the average price is zero when shop is closed and 100% when opened."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, Sale is zero when shop is not opened therefore we don't need the data when shop is closed."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "final_df.groupby(['SchoolHoliday'])['Sales'].mean().plot.pie(autopct='%0.01f%%',explode=[0,0.05],shadow= True,colors={'red','white'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart shows part to whole ralationship with the data I picked this chart to percentage of sales on holiday and non holiday for school."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average sale for holiday is 53.5% and for non holiday is 46.5%."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "School holiday leading to more sales it might be because there are lot of teenage students who are important customers."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "final_df.groupby(['StateHoliday'])['Sales'].mean().plot.pie(colors={'red','white','green'},shadow= True, autopct='%0.01f%%',explode=[.03,.03,.03,.03,.03])\n",
        "plt.xlabel('Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart shows part to whole relationship with the data I picked this chart to check percentage of sales for different types of state holiday."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For state holiday 0 sale is 46.3%, for '0' 48.3%, for a 2.3%, for b 17% and for c 14%"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, more that 90% of sales are when there is no holidays in state and state type '0'. Only few percentage of sales happened during holiday a,b,c. I think a,b,c are state festival and that day customers busy celebrating the festivals therefore those days are not good for business."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "final_df.groupby(['StoreType'])['Sales'].mean().plot.pie(shadow =True,explode=[0.03,0.03,.03,.03], autopct='%0.1f%%',colors={'red','white','green'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart express part to whole relationship with the data I picked this chart to see percentage of sales for each store type."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found that average sales for type b is highest 37% rest a,c,d are nearly 21% each."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, here I found that sales for type b shop is highest 37%. and for type a,c,d has approximately 21% therefore type b is leading towards more sales."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "final_df.groupby(['Assortment'])['Sales'].mean().plot.pie(shadow =True,explode=[0.03,0.03,.03], autopct='%0.1f%%',colors={'red','white','green'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart expresses part to whole relationship with the data I picked this chart to see percentage of sales for each type of assortments."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found that average sales for type a is 42.6%, b is 27.3% and c is 30.2%"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, average sale for type b is highest that is 42.6% so demand for this assortment type is highest."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "final_df[ (final_df['CompetitionDistance'] == final_df['CompetitionDistance'].min())\\\n",
        "         | (final_df['CompetitionDistance'] == final_df['CompetitionDistance'].max())].\\\n",
        "groupby(['CompetitionDistance'])['Sales'].mean().plot.pie(shadow =True,explode=[0.03,.03], autopct='%0.1f%%',colors={'red','white'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see effect of competition distance on average sales."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found that for min competition distance average sales is lower but for high competition distance average sale is also higher."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average Sales for min competition distance is about 5000 but for max competition it is approximately 7000."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "final_df.groupby(['Promo2'])['Sales'].mean().plot.pie(shadow =True,explode=[0.03,0.03], autopct='%0.1f%%',colors={'red','white'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart expresses part to whole relationship with data I picked this chart to see percentage of average sale for Promo2."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average sales when promo2 is yes then only 47% and when promo2 is No then 53%."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, promo2 is leading towards less sale therefore shop keeper should avoid promo2 to get more sales."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "df1_open.groupby(['year'])['Sales'].mean().plot.pie(shadow =True,explode=[0.03,0.03,.03], autopct='%0.1f%%',colors={'red','white','green'})\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pic chart expresses part to whole relationship with the data. I picked this chart to see percentage of average sale for each year."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average sale for 2013,2014 and 2015 is almost equal which is nearly 33%"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, Sales for each year is almost same."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "colors = ['violet','indigo','b','g','y','orange','r']\n",
        "plt.rcParams['figure.figsize'] = (20,5)\n",
        "top_10_sum(df1_open,'Store','Customers').plot.bar(color = colors)\n",
        "plt.ylabel('Customers')\n",
        "plt.xlabel('Store')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart shows frequency counts of values for different columns, I picked this chart to see top ten stores with highest number of customers."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store no 732 has highest number of customers , 261 has 2nd highest and 250 has least number of customers among these 10."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NO"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "top_10_sum(df1_open,'Store','Sales').plot.bar(color = colors)\n",
        "plt.ylabel('Sales')\n",
        "plt.xlabel('Store')\n",
        "plt.yticks(np.arange(1000000,20000001,5000000))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart shows frequency counts for different columns, I picked this chart to see top ten stores who made highest sales."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store number 262 made higest sale and 817 made 2nd highest but 756 made least sales among these 10."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, In chart 11 I found that shop 732 has highest number of customers but in 12th chart shop number 262 made highest sales. I think there are few customer who buys product in bulk quantity."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.rcParams['figure.figsize'] = (24,8)\n",
        "corr = final_df.corr()\n",
        "sns.heatmap(corr,annot=True, cmap= 'coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corelation chart shows relationship between variables therefore I picked this chart to check correlations."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found that our target variable Sales has -0.46 corralation with day of week, 0.89 with customers, 0.68 with open, 0.45 with Promo. Variable day of week has -0.39 correlation with customers, -0.53 with open,-0.39 with promo, -0.21with school holiday. Variable customers has correlation with 0.62 with open, 0.32 with promo and -0.15 with promo2. Variable Open has correlation 0.3 with Promo. Variable Competition Distance has correlation -0.14 with promo2 and -0.11 with Promo2SinceYear. rest of the variables have very less correlations with each other."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot "
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "drop_col = ['Store','Date','CompetitionOpenSinceMonth','CompetitionOpenSinceYear','Promo2SinceWeek',\n",
        "            'Promo2SinceYear','PromoInterval','DayOfWeek','Promo','SchoolHoliday','StateHoliday',\n",
        "            'Promo2']\n",
        "            \n",
        "sns.pairplot(final_df.drop(columns = drop_col))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pair chart gives very good visualization of realtionship between two variables which is very important to select and understand the variables I picked this chart to see the relationship between the variables."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I found that only Sales and Customers has linear relationship."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean sale for promo = 1 is greater than or equal to the mean sale when promo = 0.\n",
        "\n",
        "Mean sale is 0 when shop is closed.\n",
        "\n",
        "Mean sale for store type b is equal to mean sales of a+b+c."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "H0: promo_mean >= non_promo_mean\n",
        "\n",
        "H1: promo_mean < non_promo_mean"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "s1 = final_df[final_df['Promo']== 1]['Sales']\n",
        "s2 = final_df[final_df['Promo']== 0]['Sales']\n",
        "\n",
        "dof = len(s1)+len(s2)-2\n",
        "alpha = 1-0.05\n",
        "lower = t.ppf(alpha,dof)\n",
        "statistic, p_value = ttest_ind(s1,s2,equal_var=False, alternative='less')\n",
        "\n",
        "print('dof',dof)\n",
        "print('alpha ',alpha)\n",
        "print(f\"lower bound : {lower}\")\n",
        "print(f\"Statistic : {statistic}  p_value : {p_value}\")\n",
        "if  statistic < lower:\n",
        "  print('Null hypothesis is rejected')\n",
        "else :\n",
        "  print('Failed to reject null hypothesis')"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have done T-test to get P_value."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because my sample size and variance are not same."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Sale is 0 when shop is closed.\n",
        "\n",
        "\n",
        "H0: mean Sale = 0\n",
        "\n",
        "H1: mean Sale > 0\n",
        "\n",
        "Significance level = 0.05"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "s1 = final_df[final_df['Open'] == 0]['Sales']\n",
        "samp_mean = s1.mean()\n",
        "pop_mean = final_df['Sales'].mean()\n",
        "s = s1.std()\n",
        "n = len(s1)\n",
        "alpha = 1-0.05\n",
        "critical_value = t.ppf(alpha,n-1)\n",
        "t_statistic = (samp_mean- pop_mean)/(s/np.sqrt(n))\n",
        "\n",
        "print('Sample mean :', samp_mean)\n",
        "print('population mean :', pop_mean)\n",
        "print('s',s)\n",
        "print('n',n)\n",
        "print('alpha ',alpha)\n",
        "print('critical value ',critical_value)\n",
        "print('t_statistic ',t_statistic)\n",
        "\n",
        "if t_statistic > critical_value:\n",
        "  print('Null hypothesis is rejected')\n",
        "else :\n",
        "  print('Null hypothesis is accepted')"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have done t statistic test to obrain p_value."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the variance for sample and population were different."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean sale for store type b is equal to mean sales of a+c+d.\n",
        "\n",
        "H0: E[b] = E[a+c+d]\n",
        "\n",
        "H1: E[b] != E[a+c+d]"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "sa = final_df[final_df['StoreType'] == 'a']['Sales']\n",
        "sb = final_df[final_df['StoreType'] == 'b']['Sales']\n",
        "sc = final_df[final_df['StoreType'] == 'c']['Sales']\n",
        "sd = final_df[final_df['StoreType'] == 'd']['Sales']\n",
        "# mean1 = sb.mean()\n",
        "mean2 = sa.mean()+sc.mean()+sd.mean()\n",
        "dof = len(sa)-1\n",
        "lower = t.ppf(0.025,dof)\n",
        "upper = t.ppf(0.975,dof)\n",
        "stat,p_value = ttest_1samp(sa,mean2)\n",
        "\n",
        "print(f\"lower : {lower} and upper :{upper}\")\n",
        "print(f'Statistic :{stat} and p_value: {p_value}')\n",
        "if stat < lower or stat > upper:\n",
        "  print('Null hypothesis is rejected')\n",
        "else:\n",
        "  print('null hypothesis is accepted')"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have done t statistic test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because standard daviation of the samples were different."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df = final_df.copy()\n",
        "\n",
        "    \n",
        "# Filling nan values with mean in column CompetitionDistance\n",
        "# df['CompetitionDistance'] = df['CompetitionDistance'].fillna(df['CompetitionDistance'].mean())\n",
        "\n",
        "# Filling nan values with median in column CompetitionOpenSinceMonth and CompetitionOpenSinceYear\n",
        "df['CompetitionOpenSinceMonth'] = df['CompetitionOpenSinceMonth'].fillna(df['CompetitionOpenSinceMonth'].median())\n",
        "df['CompetitionOpenSinceYear'] = df['CompetitionOpenSinceYear'].fillna(df['CompetitionOpenSinceYear'].median())\n",
        "\n",
        "\n",
        "# dropping the columns which has more than 45% null values because already lost lot of informations and also dropping the rows\n",
        "# which has only less than 1% null values. \n",
        "col_to_drop = ['Open','Promo2SinceWeek','Promo2SinceYear','PromoInterval']\n",
        "df.drop(columns=col_to_drop,inplace=True)\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all I deleted all data when Stores were closed then I fill nan values in columns CompetitionDistance and CompetitionOpenSinceYear with median and I dropped those columns which contains more than 40% nan values. I also dropped some observations which containing less than 1% nan values. Since the Open column was containing contant value 1 therefore I decided to drop this column too."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Single variate outlier detection\n",
        "# Dropping those observations when sale is zero\n",
        "df = df[df['Sales']!=0]\n",
        "# Plotting outliers\n",
        "plt.rcParams['figure.figsize'] = (15,3)\n",
        "sns.boxplot(df['Sales'])\n",
        "plt.title('Before outlier removal')\n",
        "print(f\"Shape before outlier removal {df.shape}\")\n",
        "plt.show()\n",
        "print('')\n",
        "for i in range(1,7):\n",
        "  q1 = df['Sales'].quantile(.25)\n",
        "  q3 = df['Sales'].quantile(.75)\n",
        "  iqr = q3-q1\n",
        "  lower = q1-(1.5*iqr)\n",
        "  upper = q3+(1.5*iqr)\n",
        "  df = df[(df['Sales'] <= upper) & (df['Sales'] >= lower)]\n",
        "  sns.boxplot(df['Sales'])\n",
        "  plt.title('After The Iteration '+ str(i) +' The Shape is '+ str(df.shape))\n",
        "  plt.show()\n",
        "  print('')"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I deleted those observation when sale is 0 because when customer is 0 then sale is also 0 therefore these are some kind of outliers. Then I focused on the target column and deleted some outliers using 1.5*IQR method"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# one hot encoding for Assortment\n",
        "df['AssortmentA'] = df['Assortment'].apply(lambda data: 1 if data == 'a' else 0)\n",
        "df['AssortmentB'] = df['Assortment'].apply(lambda data: 1 if data == 'b' else 0)\n",
        "df['AssortmentC'] = df['Assortment'].apply(lambda data: 1 if data == 'c' else 0)\n",
        "\n",
        "#Store type one hot encoding\n",
        "df['StoreTypeA'] = df['StoreType'].apply(lambda data: 1 if data == 'a' else 0)\n",
        "df['StoreTypeB'] = df['StoreType'].apply(lambda data: 1 if data == 'b' else 0)\n",
        "df['StoreTypeC'] = df['StoreType'].apply(lambda data: 1 if data == 'c' else 0)\n",
        "df['StoreTypeD'] = df['StoreType'].apply(lambda data: 1 if data == 'd' else 0)\n",
        "\n",
        "# Econding StateHoliday\n",
        "df['sh_a'] = df['StateHoliday'].apply(lambda data: 1 if data == 'a' else 0)\n",
        "df['sh_b'] = df['StateHoliday'].apply(lambda data: 1 if data == 'b' else 0)\n",
        "df['sh_c'] = df['StateHoliday'].apply(lambda data: 1 if data == 'c' else 0)\n",
        "df['sh_d'] = df['StateHoliday'].apply(lambda data: 1 if data == 0 else 0)\n",
        "df['sh_e'] = df['StateHoliday'].apply(lambda data: 1 if data == '0' else 0)\n",
        "\n",
        "# Dropping the columns\n",
        "df.drop(columns =['Assortment', 'StoreType','StateHoliday'], inplace= True)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I did one hot encoding to StateHoliday, StoreType and Assortment columns because the mean price of each catagory was different."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "# from str to date time conversion\n",
        "df['Date'] = df['Date'].apply(lambda col: datetime.strptime(col,'%Y-%m-%d'))\n",
        "\n",
        "# creating day, month, year columns\n",
        "plt.rcParams['figure.figsize'] = (5,3)\n",
        "df['day'] = df['Date'].apply(lambda d: d.day)\n",
        "df['month'] = df['Date'].apply(lambda m: m.month)\n",
        "df['year'] = df['Date'].apply(lambda y: y.year)\n",
        "\n",
        "# Dropping Date column\n",
        "df.drop(columns=['Date'], inplace=True)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multicollinearity\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "metadata": {
        "id": "W9QZSXTk-2zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multicolinearitiy check\n",
        "high_vif_col = ['Store','Sales','year','AssortmentA','sh_d','StoreTypeA','sh_e','CompetitionOpenSinceYear']\n",
        "calc_vif(df[[i for i in df.describe().columns if i not in high_vif_col ]])"
      ],
      "metadata": {
        "id": "o65iu81j-8EA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "selected_features = ['DayOfWeek','Customers','Promo','SchoolHoliday','CompetitionDistance','CompetitionOpenSinceMonth','Promo2',\\\n",
        "                     'AssortmentB','AssortmentC','StoreTypeB','StoreTypeC','StoreTypeD','sh_a','sh_b','sh_c','day','month','Sales']\n",
        "selected_df = df[selected_features]"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I simply used vif method to find good featues."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choosed these feature because these has less than 7 vif scores.\n",
        "\n",
        "DayOfWeek\n",
        "\n",
        "Customers\n",
        "\n",
        "Promo\n",
        "\n",
        "SchoolHoliday\n",
        "\n",
        "CompetitionDistance\n",
        "\n",
        "CompetitionOpenSinceMonth\n",
        "\n",
        "Promo2\n",
        "\n",
        "AssortmentB\n",
        "\n",
        "AssortmentC\n",
        "\n",
        "StoreTypeB\n",
        "\n",
        "StoreTypeC\n",
        "\n",
        "StoreTypeD\n",
        "\n",
        "sh_a\n",
        "\n",
        "sh_b\n",
        "\n",
        "sh_c\n",
        "\n",
        "day\n",
        "\n",
        "month\n",
        "\n",
        "Sales\n"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "X = np.log10(selected_df[['Customers','CompetitionDistance']])\n",
        "selected_df['Customers'] = X['Customers']\n",
        "selected_df['CompetitionDistance'] = X['CompetitionDistance']\n",
        "del X"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "My data was in different range . To make them in same range data transformation is needed. Here I am using log transformation to make data more close to normal distribution."
      ],
      "metadata": {
        "id": "jqIxZ9We_70B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "standard_scaler = StandardScaler()\n",
        "X = standard_scaler.fit_transform(selected_df[['Customers','CompetitionDistance']])\n",
        "selected_df['Customers'] = X[:,0]\n",
        "selected_df['CompetitionDistance'] = X[:,1]\n",
        "del X"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I used standard scaler because my data was already close to normal distribution."
      ],
      "metadata": {
        "id": "1wDEF1foALry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I do not think in my case dimentionality reduction is needed because I already have limited features."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(random_state=0)\n",
        "X = pca.fit_transform(selected_df.drop(columns=['Sales']))\n",
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used PCA for reducing my dimentions."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "xtrain,xtest,ytrain,ytest = train_test_split(X, selected_df['Sales'], test_size=.2)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose 20% for test and rest 80% to train my model because more data is needed to train a model well."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "linearModel = LinearRegression()\n",
        "# Fit the Algorithm\n",
        "linearModel.fit(xtrain,ytrain)\n",
        "print(f\" coefficients for the model are :\\n{linearModel.coef_}\")\n",
        "print(f\" Model intercept is : {linearModel.intercept_}\")\n",
        "\n",
        "# Predict on the model\n",
        "pred_train = linearModel.predict(xtrain)\n",
        "pred_test = linearModel.predict(xtest)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linearModel.get_params()"
      ],
      "metadata": {
        "id": "-noT7WNPBnJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "def show_metrix(xtrain,ytrain,xtest,ytest):\n",
        "  pd.Series([r2_score(ytrain,pred_train),r2_score(ytest,pred_test)],\\\n",
        "          index=['Train R2_score', 'Test R2_score']).plot.bar(color=['red','green'])\n",
        "  plt.show()\n",
        "  #Printing scores\n",
        "  print(' ')\n",
        "  print(f\"R2_score train : {r2_score(ytrain,pred_train)}\")\n",
        "  print(f\"R2_score test : {r2_score(ytest,pred_test)}\\n\")\n",
        "\n",
        "  # mean squared for train and test\n",
        "  pd.Series([np.math.sqrt(mean_squared_error(ytest,pred_test)),np.math.sqrt(mean_squared_error(ytest,pred_test))],\\\n",
        "            index=['Train RMSE', 'Test RMSE']).plot.bar(color=['red','green'])\n",
        "  plt.show()\n",
        "  # Printing scores\n",
        "  print(' ')\n",
        "  print(f\"Root mean squared error train : {np.math.sqrt(mean_squared_error(ytrain,pred_train))}\")\n",
        "  print(f\"Root mean squared error test : {np.math.sqrt(mean_squared_error(ytest,pred_test))}\")"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = (20,3)\n",
        "# Metrices\n",
        "show_metrix(xtrain,ytrain,xtest,ytest)"
      ],
      "metadata": {
        "id": "9st-6ydWBvCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "grid_param = {'fit_intercept': [True,False],'positive': [True,False]}\n",
        "grid_model = GridSearchCV(linearModel,cv=10, param_grid = grid_param)\n",
        "# cross validation fitting\n",
        "grid_model.fit(xtrain,ytrain)\n",
        "bestLinearEstimator = grid_model.best_estimator_\n",
        "\n",
        "print(f\" coefficients for the model are :\\n{bestLinearEstimator.coef_}\")\n",
        "print(f\" Model intercept is : {bestLinearEstimator.intercept_}\")\n",
        "\n",
        "# Predict on the model\n",
        "pred_train = bestLinearEstimator.predict(xtrain)\n",
        "pred_test = bestLinearEstimator.predict(xtest)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_metrix(xtrain,ytrain,xtest,ytest)"
      ],
      "metadata": {
        "id": "BpkeuczZCJCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used fit_intercept and positive hyper parameters to tune the model because Linear Regression has limited hyper parameters."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I did not see any improvement."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting decission tree regressor\n",
        "dtrModel = DecisionTreeRegressor()\n",
        "dtrModel.fit(xtrain,ytrain)\n",
        "\n",
        "# Predicting\n",
        "pred_train = dtrModel.predict(xtrain)\n",
        "pred_test = dtrModel.predict(xtest)"
      ],
      "metadata": {
        "id": "AkTctp0GNB-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "show_metrix(xtrain,ytrain,xtest,ytest)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "grid_params = {'max_depth' : [13],'random_state':[1], 'min_samples_leaf': [5]}\n",
        "grid_model = GridSearchCV(estimator=dtrModel,cv= 3, param_grid=grid_params, verbose=2)\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_model.fit(xtrain,ytrain)\n",
        "bestDtrEstimator = grid_model.best_estimator_\n",
        "# Predict on the model\n",
        "pred_train = bestDtrEstimator.predict(xtrain)\n",
        "pred_test = bestDtrEstimator.predict(xtest)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used ['max_depth' : [12],'random_state':[1], 'min_samples_leaf': [5]] to avoid overfitting."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes earlier the model was overfitted but after cross validation model is good."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am using r2score to see the score of the model and root mean squared error to determine the error. r2 score for the model in train case is .85 and in test case .84. Error for train is 872 and for test is 922 so the difference is not much therefore after applying cross validation and hyper parameter tuning the model is working good."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "xgbModel = XGBRegressor(random_state=0)\n",
        "# Fit the Algorithm\n",
        "xgbModel.fit(xtrain,ytrain)\n",
        "# Predict on the model\n",
        "pred_train = xgbModel.predict(xtrain)\n",
        "pred_test = xgbModel.predict(xtest)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "show_metrix(xtrain,ytrain,xtest,ytest)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "grid_params = {'learning_rate':[.8],'random_state' :[0],'n_estimators': [120]}\n",
        "grid_model = GridSearchCV(estimator=xgbModel,cv= 5, param_grid=grid_params,verbose=2)\n",
        "\n",
        "# Fit the Algorithm\n",
        "grid_model.fit(xtrain,ytrain)\n",
        "bestXGBEstimator = grid_model.best_estimator_\n",
        "\n",
        "# Predict on the model\n",
        "pred_train = bestXGBEstimator.predict(xtrain)\n",
        "pred_test = bestXGBEstimator.predict(xtest)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_metrix(xtrain,ytrain,xtest,ytest)"
      ],
      "metadata": {
        "id": "xzUNjxcUPphf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best parameters\n",
        "grid_model.best_params_"
      ],
      "metadata": {
        "id": "zi-V8u8cPuWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'learning_rate':[.8] - to get better accuracy\n",
        "\n",
        "'random_state' :[0] - to avoid different splits\n",
        "\n",
        "'n_estimators': [120] - to get better accuracy"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the model is slightly improved and giving better scores."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R2 score to compare the scores\n",
        "\n",
        "mean squared error to compare errors."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choosed the third model for my final prediction because this model is giving highest r2 score and least error."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "explainer = shap.Explainer(bestXGBEstimator)\n",
        "shap_values = explainer(xtest)"
      ],
      "metadata": {
        "id": "WPGkC0GSQWLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize JavaScript visualizations in notebook environment\n",
        "shap.initjs()\n",
        "# Forceplot for first observation\n",
        "shap.plots.force(shap_values[0])"
      ],
      "metadata": {
        "id": "CCHhnn2JQZix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean SHAP\n",
        "shap.plots.bar(shap_values)"
      ],
      "metadata": {
        "id": "beIKylsFQeIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In bar plot for each feature we calculate mean of the absolute shap values across all observations. Feature that have large mean shap values are those features which have a huge impact on the model prediction."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Beeswarm plot\n",
        "shap.plots.beeswarm(shap_values)"
      ],
      "metadata": {
        "id": "c8fP6c36Qkq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beeswarm highlights important relationships of the features from the above chart we can see feature 5, 4,6,3,12 have very huge impact on prediction."
      ],
      "metadata": {
        "id": "SnL-81zhQtt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some solutions to predict sales\n",
        "\n",
        "Delete the observations when stores are not opened and also delete the column \n",
        "open because it will contain constant value.\n",
        "\n",
        "Target column follows normal distribution if I remove zeros from the data.\n",
        "\n",
        "Sum of the sale is least on day 7 it is because mostly on day 7 stores are not opened.\n",
        "\n",
        "Average sale is more than 60% in case of promo.\n",
        "\n",
        "Average sale is high when there is school holiday.\n",
        "\n",
        "Average sale in case of state holiday is less than 3% for each a,b and c.\n",
        "\n",
        "Average sales for store type b is highest that is 37% and for type a,c,d is approximately 21%.\n",
        "\n",
        "Average sales for assortment b is highest that is more than 42% and for a and c are 27.3% and 30.2% respectively.\n",
        "\n",
        "Average sales for promo2 is only 47%.\n",
        "\n",
        "We can deploy the model with XGBoost algorithm. Because for training and test dataset, I found 85% r2 scores, 903 and 912 root mean squared error respectively.\n",
        "\n",
        "No overfitting is seen."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}